bootstrap.servers={kafka-1 IP}:9092

# Define the converters to be used for source and sink connectors
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false

# Define the HDFS connector configuration
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max=1
topics=my-topic
hdfs.url=hdfs://{nn-1 IP}:9000
flush.size=3
format.class=io.confluent.connect.hdfs.avro.AvroFormat
schema.compatibility=BACKWARD

# Define the HDFS source configuration
# You can customize this for your CSV file
file.path=animal/animal.csv/part-00000-8c09b123-132d-4487-8a60-0ae07b5fb019-c000.csv
file.delimiter=,
topic=animal
key.ignore=true
